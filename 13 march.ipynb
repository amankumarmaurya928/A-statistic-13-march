{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ba16e0-46fc-4b9f-84af-962fa715f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ANOVA assumes that the data is normally distributed.The ANOVA also assumes homogeneity of variance,\\n   which means that the variance among the groups should be approximately equal.\\n   ANOVA also assumes that the observations are independent of each other.\\nTesting of the Assumptions\\n\\n1. The population from which samples are drawn should be normally distributed.\\n2. Independence of cases: the sample cases should be independent of each other.\\n3. Homogeneity of variance: Homogeneity means that the variance among the groups should be approximately equal.\\n  Example:\\n  Recall the application from the beginning of the lesson. We wanted to see whether the tar contents (in milligrams) \\n  for three different brands of cigarettes were different.\\n  Lab Precise and Lab Sloppy each took six samples from each of the three brands (A, B and C).\\n  '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q1\n",
    "'''ANOVA assumes that the data is normally distributed.The ANOVA also assumes homogeneity of variance,\n",
    "   which means that the variance among the groups should be approximately equal.\n",
    "   ANOVA also assumes that the observations are independent of each other.\n",
    "Testing of the Assumptions\n",
    "\n",
    "1. The population from which samples are drawn should be normally distributed.\n",
    "2. Independence of cases: the sample cases should be independent of each other.\n",
    "3. Homogeneity of variance: Homogeneity means that the variance among the groups should be approximately equal.\n",
    "  Example:\n",
    "  Recall the application from the beginning of the lesson. We wanted to see whether the tar contents (in milligrams) \n",
    "  for three different brands of cigarettes were different.\n",
    "  Lab Precise and Lab Sloppy each took six samples from each of the three brands (A, B and C).\n",
    "  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b25b3b3-531b-4d20-ad34-c5e95d1b073f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'three types of ANOVA:\\n   1. one-way ANOVA\\n   2. two-way ANOVA\\n   3. N-way ANOVA.\\nExplanation and Use:-\\n1. one way ANOVA:\\n          A one-way ANOVA has just one independent variable.\\n              For example, difference in IQ can be assessed by Country, and County can have 2, 20, or more different \\n              categories to compare.\\n\\n2. Two-Way ANOVA:\\n          A two-way ANOVA (are also called factorial ANOVA) refers to an ANOVA using two independent variables. \\n          Expanding the example above, a 2-way ANOVA can examine differences in IQ scores (the dependent variable) \\n          by Country (independent variable 1) and Gender (independent variable 2). \\n          Two-way ANOVA can be used to examine the interaction between the two independent variables. \\n          Interactions indicate that differences are not uniform across all categories of the independent variables.\\n               For example, females may have higher IQ scores overall compared to males, but this difference could be \\n               greater (or less) in European countries compared to North American countries.\\n\\n3. N-Way ANOVA\\n          A researcher can also use more than two independent variables, and this is an n-way ANOVA (with n being the \\n          number of independent variables you have).\\n               For example, potential differences in IQ scores can be examined by Country, Gender, Age group, Ethnicity,\\n               etc, simultaneously.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q2\n",
    "'''three types of ANOVA:\n",
    "   1. one-way ANOVA\n",
    "   2. two-way ANOVA\n",
    "   3. N-way ANOVA.\n",
    "Explanation and Use:-\n",
    "1. one way ANOVA:\n",
    "          A one-way ANOVA has just one independent variable.\n",
    "              For example, difference in IQ can be assessed by Country, and County can have 2, 20, or more different \n",
    "              categories to compare.\n",
    "\n",
    "2. Two-Way ANOVA:\n",
    "          A two-way ANOVA (are also called factorial ANOVA) refers to an ANOVA using two independent variables. \n",
    "          Expanding the example above, a 2-way ANOVA can examine differences in IQ scores (the dependent variable) \n",
    "          by Country (independent variable 1) and Gender (independent variable 2). \n",
    "          Two-way ANOVA can be used to examine the interaction between the two independent variables. \n",
    "          Interactions indicate that differences are not uniform across all categories of the independent variables.\n",
    "               For example, females may have higher IQ scores overall compared to males, but this difference could be \n",
    "               greater (or less) in European countries compared to North American countries.\n",
    "\n",
    "3. N-Way ANOVA\n",
    "          A researcher can also use more than two independent variables, and this is an n-way ANOVA (with n being the \n",
    "          number of independent variables you have).\n",
    "               For example, potential differences in IQ scores can be examined by Country, Gender, Age group, Ethnicity,\n",
    "               etc, simultaneously.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1260ab-43de-4c8b-8a78-246198ea3441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the variance within a group.\\nAnother way to view this problem is that we could partition variance, that is, we could divide the total variance in our \\ndata into the various sources of that variation.\\n Importance:\\n ANOVA is helpful for testing three or more variables. It is similar to multiple two-sample t-tests. However, \\n it results in fewer type I errors and is appropriate for a range of issues. ANOVA groups differences by comparing \\n the means of each group and includes spreading out the variance into diverse sources.\\n '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3\n",
    "'''An ANOVA uses an F-test to evaluate whether the variance among the groups is greater than the variance within a group.\n",
    "Another way to view this problem is that we could partition variance, that is, we could divide the total variance in our \n",
    "data into the various sources of that variation.\n",
    " Importance:\n",
    " ANOVA is helpful for testing three or more variables. It is similar to multiple two-sample t-tests. However, \n",
    " it results in fewer type I errors and is appropriate for a range of issues. ANOVA groups differences by comparing \n",
    " the means of each group and includes spreading out the variance into diverse sources.\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff408e26-bc3c-4fd0-a2ca-8ad32ecc5778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SST:\\nThe sum of squares total, denoted SST, is the squared differences between the observed dependent variable and its mean. \\nYou can think of this as the dispersion of the observed variables around the mean – much like the variance in descriptive \\nstatistics.\\n\\nSSE:\\nThe last term is the sum of squares error, or SSE. The error is the difference between the observed value and the predicted\\nvalue.\\nWe usually want to minimize the error. The smaller the error, the better the estimation power of the regression.\\nFinally, I should add that it is also known as RSS or residual sum of squares. Residual as in: remaining or unexplained.\\n\\nSSR:\\nThe second term is the sum of squares due to regression, or SSR. It is the sum of the differences between the predicted value\\nand the mean of the dependent variable. Think of it as a measure that describes how well our line fits the data.\\nIf this value of SSR is equal to the sum of squares total, it means our regression model captures all the observed variability\\nand is perfect. Once again, we have to mention that another common notation is ESS or explained sum of squares.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4\n",
    "'''SST:\n",
    "The sum of squares total, denoted SST, is the squared differences between the observed dependent variable and its mean. \n",
    "You can think of this as the dispersion of the observed variables around the mean – much like the variance in descriptive \n",
    "statistics.\n",
    "\n",
    "SSE:\n",
    "The last term is the sum of squares error, or SSE. The error is the difference between the observed value and the predicted\n",
    "value.\n",
    "We usually want to minimize the error. The smaller the error, the better the estimation power of the regression.\n",
    "Finally, I should add that it is also known as RSS or residual sum of squares. Residual as in: remaining or unexplained.\n",
    "\n",
    "SSR:\n",
    "The second term is the sum of squares due to regression, or SSR. It is the sum of the differences between the predicted value\n",
    "and the mean of the dependent variable. Think of it as a measure that describes how well our line fits the data.\n",
    "If this value of SSR is equal to the sum of squares total, it means our regression model captures all the observed variability\n",
    "and is perfect. Once again, we have to mention that another common notation is ESS or explained sum of squares.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc25938b-230e-4cdc-aa5e-f23a9b1c8cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum_sq</th>\n",
       "      <th>df</th>\n",
       "      <th>F</th>\n",
       "      <th>PR(&gt;F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C(water)</th>\n",
       "      <td>8.533333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0.000527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(sun)</th>\n",
       "      <td>24.866667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.3125</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C(water):C(sun)</th>\n",
       "      <td>2.466667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.3125</td>\n",
       "      <td>0.120667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual</th>\n",
       "      <td>12.800000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sum_sq    df        F    PR(>F)\n",
       "C(water)          8.533333   1.0  16.0000  0.000527\n",
       "C(sun)           24.866667   2.0  23.3125  0.000002\n",
       "C(water):C(sun)   2.466667   2.0   2.3125  0.120667\n",
       "Residual         12.800000  24.0      NaN       NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5\n",
    "'''How to Perform a Two-Way ANOVA in Python\n",
    "Step 1: Enter the data. First, we'll create a pandas DataFrame that contain variables.\n",
    "Step 2: Perform the two-way ANOVA. we’ll perform the two-way ANOVA using the anova_lm() function\n",
    "Step 3: Interpret the results. We can see the following p-values for each of the factors in the table: \n",
    "    Example:'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'water': np.repeat(['daily', 'weekly'], 15),\n",
    "                   'sun': np.tile(np.repeat(['low', 'med', 'high'], 5), 2),\n",
    "                   'height': [6, 6, 6, 5, 6, 5, 5, 6, 4, 5,\n",
    "                              6, 6, 7, 8, 7, 3, 4, 4, 4, 5,\n",
    "                              4, 4, 4, 4, 4, 5, 6, 6, 7, 8]})\n",
    "\n",
    "df[:10]\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols('height ~ C(water) + C(sun) + C(water):C(sun)', data=df).fit()\n",
    "sm.stats.anova_lm(model, typ=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8327a0c2-782c-4f66-8448-743dd75d3033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The lower the p value is for a given ratio, the more reliably we can reject the null hypothesis that a particular \\n source or model or parameter is not significant. In most cases, the F (or variance) ratio involves comparing one source\\n of error or variation against the replicate (or analytical) error.\\nA good rule of thumb is to accept very extreme p values (.02 or less) as a convincing rejection of the null hypothesis,\\nbut where the p values are somewhat higher, to perform other tests as well to back up the hypothesis.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6\n",
    "'''The lower the p value is for a given ratio, the more reliably we can reject the null hypothesis that a particular \n",
    " source or model or parameter is not significant. In most cases, the F (or variance) ratio involves comparing one source\n",
    " of error or variation against the replicate (or analytical) error.\n",
    "A good rule of thumb is to accept very extreme p values (.02 or less) as a convincing rejection of the null hypothesis,\n",
    "but where the p values are somewhat higher, to perform other tests as well to back up the hypothesis.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c42df0-e496-491e-b7a1-189e16f9b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of the most effective ways of dealing with missing data is multiple imputation (MI). Using MI, we can create \\nmultiple plausible replacements of the missing data, given what we have observed and a statistical model \\n(the imputation model).\\nOne of the biggest problems with traditional repeated measures ANOVA is missing data on the response variable. \\nThe problem is that repeated measures ANOVA treats each measurement as a separate variable. Because it uses listwise\\ndeletion, if one measurement is missing, the entire case gets dropped.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q7\n",
    "'''One of the most effective ways of dealing with missing data is multiple imputation (MI). Using MI, we can create \n",
    "multiple plausible replacements of the missing data, given what we have observed and a statistical model \n",
    "(the imputation model).\n",
    "One of the biggest problems with traditional repeated measures ANOVA is missing data on the response variable. \n",
    "The problem is that repeated measures ANOVA treats each measurement as a separate variable. Because it uses listwise\n",
    "deletion, if one measurement is missing, the entire case gets dropped.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875650a5-8009-4e30-88b3-81a35a18b92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Post Hoc tests are used as a follow-up to the ANOVA to determine which pairwise comparison of means contributes \\nto the overall significant difference that is observed in the computation of the F statistic.\\nFor ANOVA, you can use one of several post hoc tests, each which control for Type I Error, while performing paired \\ncomparisons (Duncan Multiple Range test, Dunnett's Multiple Comparison test, Newman-Keuls test, Scheffe's test, \\nTukey's HSD test, Fisher's LSD test, Sidak).\\nPost-hoc tests: Examples\\nBonferroni's test.\\nTukey's honest significant difference test.\\nScheffe's test.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q8\n",
    "'''Post Hoc tests are used as a follow-up to the ANOVA to determine which pairwise comparison of means contributes \n",
    "to the overall significant difference that is observed in the computation of the F statistic.\n",
    "For ANOVA, you can use one of several post hoc tests, each which control for Type I Error, while performing paired \n",
    "comparisons (Duncan Multiple Range test, Dunnett's Multiple Comparison test, Newman-Keuls test, Scheffe's test, \n",
    "Tukey's HSD test, Fisher's LSD test, Sidak).\n",
    "Post-hoc tests: Examples\n",
    "Bonferroni's test.\n",
    "Tukey's honest significant difference test.\n",
    "Scheffe's test.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0d8661-3df9-445e-80f0-16678d506365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given :\\n   n = 50, alpha = 0.05\\n   1. null hypothesis H0  variance1 = variance2\\n      alternate hypothesis H1  variance1 != variance2\\n   2. Calculation of variance:\\n             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\\n            \\n   3. Calcullating of variance ratio (F test):\\n           F = S1/S2\\n   4. Decision rule:\\n        Df1 = 50-1 = 49\\n     if F test score is greater than 3.49 , reject the null hypothesis\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q9\n",
    "'''Given :\n",
    "   n = 50, alpha = 0.05\n",
    "   1. null hypothesis H0  variance1 = variance2\n",
    "      alternate hypothesis H1  variance1 != variance2\n",
    "   2. Calculation of variance:\n",
    "             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\n",
    "            \n",
    "   3. Calcullating of variance ratio (F test):\n",
    "           F = S1/S2\n",
    "   4. Decision rule:\n",
    "        Df1 = 50-1 = 49\n",
    "     if F test score is greater than 3.49 , reject the null hypothesis\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "536b35dd-2234-422f-83f5-fd3587f6179b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given :\\n   n = 30, alpha = 0.05\\n   1. null hypothesis H0  variance1 = variance2\\n      alternate hypothesis H1  variance1 != variance2\\n   2. Calculation of variance:\\n             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\\n            \\n   3. Calcullating of variance ratio (F test):\\n           F = S1/S2\\n   4. Decision rule:\\n        Df1 = 30-1 = 29\\n     if F test score is greater than 3.49 , reject the null hypothesis\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q10\n",
    "'''Given :\n",
    "   n = 30, alpha = 0.05\n",
    "   1. null hypothesis H0  variance1 = variance2\n",
    "      alternate hypothesis H1  variance1 != variance2\n",
    "   2. Calculation of variance:\n",
    "             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\n",
    "            \n",
    "   3. Calcullating of variance ratio (F test):\n",
    "           F = S1/S2\n",
    "   4. Decision rule:\n",
    "        Df1 = 30-1 = 29\n",
    "     if F test score is greater than 3.49 , reject the null hypothesis\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff77fa61-fdc9-4529-9983-e83f0dc131a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Given :\\n   n = 100, alpha = 0.05\\n   1. null hypothesis H0  variance1 = variance2\\n      alternate hypothesis H1  variance1 != variance2\\n   2. Calculation of variance:\\n             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\\n            \\n   3. Calcullating of variance ratio (F test):\\n           F = S1/S2\\n   4. Decision rule:\\n        Df1 = 100-1 = 99\\n     if F test score is greater than 3.49 , reject the null hypothesis\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q11\n",
    "'''Given :\n",
    "   n = 100, alpha = 0.05\n",
    "   1. null hypothesis H0  variance1 = variance2\n",
    "      alternate hypothesis H1  variance1 != variance2\n",
    "   2. Calculation of variance:\n",
    "             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\n",
    "            \n",
    "   3. Calcullating of variance ratio (F test):\n",
    "           F = S1/S2\n",
    "   4. Decision rule:\n",
    "        Df1 = 100-1 = 99\n",
    "     if F test score is greater than 3.49 , reject the null hypothesis\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8c7810-29c9-4149-acfd-4ab3d7138061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q12\n",
    "'''Given :\n",
    "   the three retail stores: Store A, Store B, and Store C. \n",
    "   n = 50, alpha = 0.05\n",
    "   1. null hypothesis H0  variance1 = variance2\n",
    "      alternate hypothesis H1  variance1 != variance2\n",
    "   2. Calculation of variance:\n",
    "             S^2 = sum of all (i=1 to n) (Xi - mean)^2/(n-1)\n",
    "            \n",
    "   3. Calcullating of variance ratio (F test):\n",
    "           F = S1/S2\n",
    "   4. Decision rule:\n",
    "        Df1 = 50-1 = 49\n",
    "     if F test score is greater than 3.49 , reject the null hypothesis\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
